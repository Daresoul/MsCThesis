{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip3 install spacy\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:09:54.135309Z",
     "start_time": "2024-05-23T20:09:54.132943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:09:54.137458Z",
     "start_time": "2024-05-23T20:09:54.135935Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_length = 64\n",
    "bert_name = \"bert-large-uncased\"\n",
    "nltk_name = 'averaged_perceptron_tagger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:09:54.140829Z",
     "start_time": "2024-05-23T20:09:54.138160Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacy_to_nltk = {\n",
    "    \"ADJ\": [\"JJ\", \"JJR\", \"JJS\"],\n",
    "    \"ADP\": [\"IN\", \"TO\"],\n",
    "    \"ADV\": [\"RB\", \"RBR\", \"RBS\"],\n",
    "    \"AUX\": [\"MD\"],\n",
    "    \"CONJ\": [\"CC\"],\n",
    "    \"CCONJ\": [\"CC\"],\n",
    "    \"DET\": [\"DT\", \"PDT\", \"WDT\"],\n",
    "    \"INTJ\": [],\n",
    "    \"NOUN\": [\"NN\", \"NNS\"],\n",
    "    \"NUM\": [],\n",
    "    \"PART\": [\"POS\", \"RP\", \"TO\"],\n",
    "    \"PRON\": [],\n",
    "    \"PROPN\": [\"NNP\", \"NNPS\"],\n",
    "    \"PUNCT\": [\".\", \",\", \":\", \"(\", \")\", \"''\", \"``\"],\n",
    "    \"SCONJ\": [\"IN\"],\n",
    "    \"SYM\": [],\n",
    "    \"VERB\": [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"],\n",
    "    \"X\": [],\n",
    "    \"SPACE\": []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "label2id = defaultdict(int, {\n",
    "    \"ADJ\": 0,\n",
    "    \"ADP\": 1,\n",
    "    \"ADV\": 2,\n",
    "    \"AUX\": 3,\n",
    "    \"CONJ\": 4,\n",
    "    \"CCONJ\": 5,\n",
    "    \"DET\": 6,\n",
    "    \"INTJ\": 7,\n",
    "    \"NOUN\": 8,\n",
    "    \"NUM\": 9,\n",
    "    \"PART\": 10,\n",
    "    \"PRON\": 11,\n",
    "    \"PROPN\": 12,\n",
    "    \"PUNCT\": 13,\n",
    "    \"SCONJ\": 14,\n",
    "    \"SYM\": 15,\n",
    "    \"VERB\": 16,\n",
    "    \"X\": 17,\n",
    "    \"SPACE\": 18\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:09:55.169950Z",
     "start_time": "2024-05-23T20:09:54.142104Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tomato/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(bert_name)\n",
    "nltk.download(nltk_name)\n",
    "\n",
    "def extract_data(path: str, filename: str):\n",
    "    if filename.endswith('.html'):\n",
    "        data = open(path + \"/\" + filename, mode=\"r\", encoding=\"UTF-8\").read()\n",
    "        return data\n",
    "    return ''\n",
    "\n",
    "def extract_all_data(dataset: pd.DataFrame, path: str):\n",
    "    return [extract_data(path, x) for x in dataset['Filename']]\n",
    "\n",
    "def normalize_text(text: str):\n",
    "    return (text\n",
    "            .lower()\n",
    "            .replace(\"\\n\", \"\")\n",
    "            )\n",
    "\n",
    "def split_on_period(arr, math_tokens):\n",
    "    result_toks = []\n",
    "    current_toks = []\n",
    "\n",
    "    result_index = []\n",
    "    current_index = []\n",
    "\n",
    "    tok_number = 0\n",
    "\n",
    "    for i, item in enumerate(arr):\n",
    "        current_toks.append(item)\n",
    "\n",
    "        if i in math_tokens:\n",
    "            current_index.append(tok_number)\n",
    "\n",
    "        tok_number += 1\n",
    "        if item.strip() == '.':\n",
    "            result_toks.append(current_toks)\n",
    "            result_index.append(current_index)\n",
    "            current_toks = []\n",
    "            current_index = []\n",
    "            tok_number = 0\n",
    "\n",
    "    if current_toks:\n",
    "        result_toks.append(current_toks)\n",
    "        result_index.append(current_index)\n",
    "\n",
    "    return result_toks, result_index\n",
    "\n",
    "def tokenize(paragraph):\n",
    "    toks = []\n",
    "    math_index = []\n",
    "    for content in paragraph.contents:\n",
    "        if content.name is not None:\n",
    "            if content.name == \"mml:math\":\n",
    "                math_index.append(len(toks))\n",
    "                toks.append(\"[MATH]\")\n",
    "            if content.name == \"ce:display\":\n",
    "                math_index.append(len(toks))\n",
    "                toks.append(\"[DISPLAY]\")\n",
    "            elif content.name == \"ce:italic\":\n",
    "                if len(content.text) > 2:\n",
    "                    content = normalize_text(content.text)\n",
    "                    textToks = nltk.word_tokenize(content)\n",
    "                    toks.extend(textToks)\n",
    "                    continue\n",
    "                math_index.append(len(toks))\n",
    "                toks.append(\"[ITALIC]\")\n",
    "            elif content.name == \"ce:cross-refs\":\n",
    "                continue\n",
    "        else:\n",
    "            content = normalize_text(content)\n",
    "            textToks = nltk.word_tokenize(content)\n",
    "            toks.extend(textToks)\n",
    "\n",
    "    return split_on_period(toks, math_index)\n",
    "\n",
    "def tokenize_file(row):\n",
    "    filename = row[\"Filename\"]\n",
    "    complete_text = row[\"CompleteText\"]\n",
    "\n",
    "    data = {\n",
    "        \"file_name\": [],\n",
    "        \"title\": [],\n",
    "        \"tokens\": [],\n",
    "        \"math_index\": [],\n",
    "    }\n",
    "\n",
    "    soup = BeautifulSoup(complete_text)\n",
    "    for section in soup.find_all(\"ce:section\"):\n",
    "        title = section.find_next(\"ce:section-title\").text\n",
    "        for paragraph in section.find_all(\"ce:para\"):\n",
    "            toks_arr, math_toks_arr = tokenize(paragraph)\n",
    "            for toks, math_toks in zip(toks_arr, math_toks_arr):\n",
    "                \n",
    "                if len(toks) == 0 or len(math_toks) == 0:\n",
    "                    continue\n",
    "                data[\"tokens\"].append(toks)\n",
    "                data[\"title\"].append(title)\n",
    "                data[\"file_name\"].append(filename)\n",
    "                data[\"math_index\"].append(math_toks)\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.word_tokenize(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "fileList = np.array(os.listdir(path))\n",
    "dataset = pd.DataFrame(fileList, columns=['Filename'])\n",
    "dataset[\"CompleteText\"] = extract_all_data(dataset, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([tokenize_file(row) for _, row in tqdm(dataset.iterrows(), total=len(dataset), desc='Processing Rows')], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_non_empty = df[df['tokens'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_empty['nltk_annotate'] = df_non_empty.progress_apply(lambda row: [x[1] for x in nltk.pos_tag(row['tokens'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = len(df_non_empty)\n",
    "dataset = ds.Dataset.from_pandas(df_non_empty)\n",
    "dataset.save_to_disk('full_df_non_empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SAVE POINT\n",
    "# SAVE POINT\n",
    "# SAVE POINT\n",
    "#\n",
    "\n",
    "from datasets import load_from_disk\n",
    "df_non_empty = load_from_disk(f'full_df_non_empty').to_pandas()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_empty['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens in enumerate(df_non_empty['tokens']):\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    for j, token in enumerate(tokens):\n",
    "        if token == '':\n",
    "            print(i, \":\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacy.require_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "special_case_math = [{ORTH: \"[MATH]\"}]\n",
    "special_case_display = [{ORTH: \"[DISPLAY]\"}]\n",
    "special_case_italic = [{ORTH: \"[ITALIC]\"}]\n",
    "nlp.tokenizer.add_special_case(\"[MATH]\", special_case_math)\n",
    "nlp.tokenizer.add_special_case(\"[DISPLAY]\", special_case_display)\n",
    "nlp.tokenizer.add_special_case(\"[ITALIC]\", special_case_italic)\n",
    "def spacy_annotate_row(row):\n",
    "    tokens = row['tokens']\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    doc = spacy.tokens.Doc(nlp.vocab, words=tokens)\n",
    "    \n",
    "    for name, proc in nlp.pipeline:\n",
    "        doc = proc(doc)\n",
    "    \n",
    "    anno = []\n",
    "    spacy_toks = []\n",
    "    for token in doc:\n",
    "        spacy_toks.append(token.text)\n",
    "        anno.append(token.pos_)\n",
    "    return anno\n",
    "\n",
    "df_non_empty['spacy'] = df_non_empty.progress_apply(spacy_annotate_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = len(df_non_empty)\n",
    "dataset = ds.Dataset.from_pandas(df_non_empty)\n",
    "dataset.save_to_disk('full_df_non_empty_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:10:10.852337Z",
     "start_time": "2024-05-23T20:10:02.134843Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_from_disk\n",
    "df_non_empty = load_from_disk(f'full_df_non_empty_spacy').to_pandas()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:10:10.872166Z",
     "start_time": "2024-05-23T20:10:10.854555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>math_index</th>\n",
       "      <th>nltk_annotate</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[for, example, ,, it, was, shown, in, that, in...</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[IN, NN, ,, PRP, VBD, VBN, IN, DT, IN, DT, NN,...</td>\n",
       "      <td>[ADP, NOUN, PUNCT, PRON, AUX, VERB, ADP, PRON,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[there, is, also, a, bijection, to, basic, clu...</td>\n",
       "      <td>[16, 20, 38]</td>\n",
       "      <td>[EX, VBZ, RB, DT, NN, TO, VB, NN, VBG, NNS, IN...</td>\n",
       "      <td>[PRON, VERB, ADV, DET, NOUN, ADP, ADJ, NOUN, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[for, an, integer, [MATH], ,, the, notion, of,...</td>\n",
       "      <td>[3, 8]</td>\n",
       "      <td>[IN, DT, NN, NN, ,, DT, NN, IN, NNP, JJ, NNS, ...</td>\n",
       "      <td>[ADP, DET, NOUN, ADJ, PUNCT, DET, NOUN, ADP, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[in, a, [ITALIC], -abelian, category, ,, kerne...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[IN, DT, JJ, JJ, NN, ,, NNS, ,, NNS, CC, NNS, ...</td>\n",
       "      <td>[ADP, DET, NOUN, ADJ, NOUN, PUNCT, NOUN, PUNCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[the, notion, of, wide, subcategories, was, ge...</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[DT, NN, IN, JJ, NNS, VBD, VBN, TO, VB, JJ, NN...</td>\n",
       "      <td>[DET, NOUN, ADP, ADJ, NOUN, AUX, VERB, ADP, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029492</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Second order energy estimates</td>\n",
       "      <td>[then, ,, we, regard, [MATH], as, the, initial...</td>\n",
       "      <td>[4, 19, 27]</td>\n",
       "      <td>[RB, ,, PRP, VBP, PRP, IN, DT, JJ, NN, CC, NN,...</td>\n",
       "      <td>[ADV, PUNCT, PRON, VERB, ADJ, ADP, DET, ADJ, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029493</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Second order energy estimates</td>\n",
       "      <td>[this, is, a, contradiction, to, the, definiti...</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>[DT, VBZ, DT, NN, TO, DT, NN, IN, NNP, ,, RB, ...</td>\n",
       "      <td>[PRON, AUX, DET, NOUN, ADP, DET, NOUN, ADP, AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029494</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Second order energy estimates</td>\n",
       "      <td>[therefore, -, has, a, unique, solution, [MATH...</td>\n",
       "      <td>[6, 8, 10]</td>\n",
       "      <td>[RB, :, VBZ, DT, JJ, NN, NN, IN, NN, IN, NN, .]</td>\n",
       "      <td>[ADV, PUNCT, VERB, DET, ADJ, NOUN, ADJ, ADP, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029495</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Second order energy estimates</td>\n",
       "      <td>[moreover, ,, let, [DISPLAY], differentiating,...</td>\n",
       "      <td>[3, 8, 14, 25, 27]</td>\n",
       "      <td>[RB, ,, VB, NNP, VBG, IN, NN, TO, VB, ,, PRP, ...</td>\n",
       "      <td>[ADV, PUNCT, VERB, X, VERB, ADP, NOUN, ADP, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029496</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Second order energy estimates</td>\n",
       "      <td>[then, ,, it, follows, from, that, [DISPLAY], ...</td>\n",
       "      <td>[6, 11, 14]</td>\n",
       "      <td>[RB, ,, PRP, VBZ, IN, DT, NN, IN, DT, JJ, JJ, ...</td>\n",
       "      <td>[ADV, PUNCT, PRON, VERB, ADP, PRON, X, ADP, DE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2029497 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name                          title  \\\n",
       "0        1375.html                   Introduction   \n",
       "1        1375.html                   Introduction   \n",
       "2        1375.html                   Introduction   \n",
       "3        1375.html                   Introduction   \n",
       "4        1375.html                   Introduction   \n",
       "...            ...                            ...   \n",
       "2029492  4226.html  Second order energy estimates   \n",
       "2029493  4226.html  Second order energy estimates   \n",
       "2029494  4226.html  Second order energy estimates   \n",
       "2029495  4226.html  Second order energy estimates   \n",
       "2029496  4226.html  Second order energy estimates   \n",
       "\n",
       "                                                    tokens  \\\n",
       "0        [for, example, ,, it, was, shown, in, that, in...   \n",
       "1        [there, is, also, a, bijection, to, basic, clu...   \n",
       "2        [for, an, integer, [MATH], ,, the, notion, of,...   \n",
       "3        [in, a, [ITALIC], -abelian, category, ,, kerne...   \n",
       "4        [the, notion, of, wide, subcategories, was, ge...   \n",
       "...                                                    ...   \n",
       "2029492  [then, ,, we, regard, [MATH], as, the, initial...   \n",
       "2029493  [this, is, a, contradiction, to, the, definiti...   \n",
       "2029494  [therefore, -, has, a, unique, solution, [MATH...   \n",
       "2029495  [moreover, ,, let, [DISPLAY], differentiating,...   \n",
       "2029496  [then, ,, it, follows, from, that, [DISPLAY], ...   \n",
       "\n",
       "                 math_index  \\\n",
       "0                      [21]   \n",
       "1              [16, 20, 38]   \n",
       "2                    [3, 8]   \n",
       "3                       [2]   \n",
       "4                       [8]   \n",
       "...                     ...   \n",
       "2029492         [4, 19, 27]   \n",
       "2029493             [8, 12]   \n",
       "2029494          [6, 8, 10]   \n",
       "2029495  [3, 8, 14, 25, 27]   \n",
       "2029496         [6, 11, 14]   \n",
       "\n",
       "                                             nltk_annotate  \\\n",
       "0        [IN, NN, ,, PRP, VBD, VBN, IN, DT, IN, DT, NN,...   \n",
       "1        [EX, VBZ, RB, DT, NN, TO, VB, NN, VBG, NNS, IN...   \n",
       "2        [IN, DT, NN, NN, ,, DT, NN, IN, NNP, JJ, NNS, ...   \n",
       "3        [IN, DT, JJ, JJ, NN, ,, NNS, ,, NNS, CC, NNS, ...   \n",
       "4        [DT, NN, IN, JJ, NNS, VBD, VBN, TO, VB, JJ, NN...   \n",
       "...                                                    ...   \n",
       "2029492  [RB, ,, PRP, VBP, PRP, IN, DT, JJ, NN, CC, NN,...   \n",
       "2029493  [DT, VBZ, DT, NN, TO, DT, NN, IN, NNP, ,, RB, ...   \n",
       "2029494    [RB, :, VBZ, DT, JJ, NN, NN, IN, NN, IN, NN, .]   \n",
       "2029495  [RB, ,, VB, NNP, VBG, IN, NN, TO, VB, ,, PRP, ...   \n",
       "2029496  [RB, ,, PRP, VBZ, IN, DT, NN, IN, DT, JJ, JJ, ...   \n",
       "\n",
       "                                                     spacy  \n",
       "0        [ADP, NOUN, PUNCT, PRON, AUX, VERB, ADP, PRON,...  \n",
       "1        [PRON, VERB, ADV, DET, NOUN, ADP, ADJ, NOUN, N...  \n",
       "2        [ADP, DET, NOUN, ADJ, PUNCT, DET, NOUN, ADP, P...  \n",
       "3        [ADP, DET, NOUN, ADJ, NOUN, PUNCT, NOUN, PUNCT...  \n",
       "4        [DET, NOUN, ADP, ADJ, NOUN, AUX, VERB, ADP, NO...  \n",
       "...                                                    ...  \n",
       "2029492  [ADV, PUNCT, PRON, VERB, ADJ, ADP, DET, ADJ, N...  \n",
       "2029493  [PRON, AUX, DET, NOUN, ADP, DET, NOUN, ADP, AD...  \n",
       "2029494  [ADV, PUNCT, VERB, DET, ADJ, NOUN, ADJ, ADP, N...  \n",
       "2029495  [ADV, PUNCT, VERB, X, VERB, ADP, NOUN, ADP, NO...  \n",
       "2029496  [ADV, PUNCT, PRON, VERB, ADP, PRON, X, ADP, DE...  \n",
       "\n",
       "[2029497 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:10:54.267103Z",
     "start_time": "2024-05-23T20:10:10.872877Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(df_non_empty)):\n",
    "    index = i\n",
    "    spacy_notation = df_non_empty.iloc[index]['spacy']\n",
    "    nltk_notation = df_non_empty.iloc[index]['nltk_annotate']\n",
    "    tokens = df_non_empty.iloc[index]['tokens']\n",
    "    if not(len(tokens) == len(spacy_notation) == len(nltk_notation)):\n",
    "        print(len(tokens))\n",
    "        print(len(spacy_notation))\n",
    "        print(len(nltk_notation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:06.178436Z",
     "start_time": "2024-05-23T20:10:54.269266Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b445971affae42e3b155e8f94678e1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_spacy_to_nltk(row):\n",
    "    tags = row['spacy']\n",
    "    nltk_tags = row['nltk_annotate']\n",
    "    math_ids = row['math_index'].astype(int)\n",
    "    return [nltk_tags[i] in spacy_to_nltk[tags[i]] for i in math_ids]\n",
    "df_non_empty['is_valid'] = df_non_empty.progress_apply(check_spacy_to_nltk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:30.057206Z",
     "start_time": "2024-05-23T20:11:06.179261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39dc7d28b5a45679543f313095c5d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Rows:   0%|          | 0/2029497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = []\n",
    "\n",
    "for i, row in tqdm(df_non_empty.iterrows(), total=len(df_non_empty), desc='Processing Rows'):\n",
    "    y.append(all(row['is_valid']) and 'X' not in row['spacy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:30.421647Z",
     "start_time": "2024-05-23T20:11:30.058039Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting len: 2029497 \n",
      "matching: 76975 \n",
      "not matching: 1952522\n"
     ]
    }
   ],
   "source": [
    "df_matching = df_non_empty[y]\n",
    "df_not_matching = df_non_empty[[not x for x in y]]\n",
    "print(\"Starting len:\", len(df_non_empty),\"\\nmatching:\", len(df_matching), \"\\nnot matching:\", len(df_not_matching))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:30.431768Z",
     "start_time": "2024-05-23T20:11:30.422281Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>math_index</th>\n",
       "      <th>nltk_annotate</th>\n",
       "      <th>spacy</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[recently, ,, higher, auslander, algebras, of,...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[RB, ,, JJR, NN, NNS, IN, NN, NNS, VBP, VBN, V...</td>\n",
       "      <td>[ADV, PUNCT, ADJ, NOUN, NOUN, ADP, NOUN, NOUN,...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[we, call, [MATH], krull-schmidt, if, each, ob...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[PRP, VBP, JJ, JJ, IN, DT, NN, VBZ, IN, DT, JJ...</td>\n",
       "      <td>[PRON, VERB, ADJ, NOUN, SCONJ, DET, NOUN, VERB...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[moreover, ,, this, d-kernel, appears, as, a, ...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...</td>\n",
       "      <td>[ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[moreover, ,, this, d-cokernel, appears, as, a...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...</td>\n",
       "      <td>[ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[(, 3, ), existence, of, [MATH], follows, in, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[(, CD, ), NN, IN, NN, VBZ, IN, DT, JJ, NN, IN...</td>\n",
       "      <td>[PUNCT, NUM, PUNCT, NOUN, ADP, NOUN, VERB, ADP...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028828</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[let, d, be, a, primitive, centralizer, of, u,...</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[VB, NN, VB, DT, JJ, NN, IN, JJ, CC, JJ, VB, D...</td>\n",
       "      <td>[VERB, NOUN, AUX, DET, ADJ, NOUN, ADP, PROPN, ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028833</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[as, [ITALIC], is, invertible, ,, this, can, n...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[IN, NN, VBZ, JJ, ,, DT, MD, RB, VB, DT, NN, .]</td>\n",
       "      <td>[SCONJ, NOUN, AUX, ADJ, PUNCT, PRON, AUX, PART...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028847</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[finally, ,, a, square, matrix, [ITALIC], is, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[RB, ,, DT, JJ, NN, NN, VBZ, VBN, DT, NN, IN, ...</td>\n",
       "      <td>[ADV, PUNCT, DET, ADJ, NOUN, NOUN, AUX, VERB, ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028864</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[assuming, (, 2, ), and, taking, [MATH], yield...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[VBG, (, CD, ), CC, VBG, JJ, NNS, (, CD, ), .]</td>\n",
       "      <td>[VERB, PUNCT, NUM, PUNCT, CCONJ, VERB, ADJ, NO...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029254</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Stability of steady-state</td>\n",
       "      <td>[next, ,, we, will, use, the, following, eight...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[JJ, ,, PRP, MD, VB, DT, JJ, CD, NNS, TO, VB, ...</td>\n",
       "      <td>[ADV, PUNCT, PRON, AUX, VERB, DET, VERB, NUM, ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76975 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name                      title  \\\n",
       "13       1375.html               Introduction   \n",
       "31       1375.html              Preliminaries   \n",
       "64       1375.html              Preliminaries   \n",
       "67       1375.html              Preliminaries   \n",
       "78       1375.html              Preliminaries   \n",
       "...            ...                        ...   \n",
       "2028828  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028833  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028847  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028864  1024.html     Proof of Theorem 4.4\\n   \n",
       "2029254  4226.html  Stability of steady-state   \n",
       "\n",
       "                                                    tokens math_index  \\\n",
       "13       [recently, ,, higher, auslander, algebras, of,...        [7]   \n",
       "31       [we, call, [MATH], krull-schmidt, if, each, ob...        [2]   \n",
       "64       [moreover, ,, this, d-kernel, appears, as, a, ...       [14]   \n",
       "67       [moreover, ,, this, d-cokernel, appears, as, a...       [14]   \n",
       "78       [(, 3, ), existence, of, [MATH], follows, in, ...        [5]   \n",
       "...                                                    ...        ...   \n",
       "2028828  [let, d, be, a, primitive, centralizer, of, u,...       [16]   \n",
       "2028833  [as, [ITALIC], is, invertible, ,, this, can, n...        [1]   \n",
       "2028847  [finally, ,, a, square, matrix, [ITALIC], is, ...        [5]   \n",
       "2028864  [assuming, (, 2, ), and, taking, [MATH], yield...        [6]   \n",
       "2029254  [next, ,, we, will, use, the, following, eight...       [15]   \n",
       "\n",
       "                                             nltk_annotate  \\\n",
       "13       [RB, ,, JJR, NN, NNS, IN, NN, NNS, VBP, VBN, V...   \n",
       "31       [PRP, VBP, JJ, JJ, IN, DT, NN, VBZ, IN, DT, JJ...   \n",
       "64       [RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...   \n",
       "67       [RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...   \n",
       "78       [(, CD, ), NN, IN, NN, VBZ, IN, DT, JJ, NN, IN...   \n",
       "...                                                    ...   \n",
       "2028828  [VB, NN, VB, DT, JJ, NN, IN, JJ, CC, JJ, VB, D...   \n",
       "2028833    [IN, NN, VBZ, JJ, ,, DT, MD, RB, VB, DT, NN, .]   \n",
       "2028847  [RB, ,, DT, JJ, NN, NN, VBZ, VBN, DT, NN, IN, ...   \n",
       "2028864     [VBG, (, CD, ), CC, VBG, JJ, NNS, (, CD, ), .]   \n",
       "2029254  [JJ, ,, PRP, MD, VB, DT, JJ, CD, NNS, TO, VB, ...   \n",
       "\n",
       "                                                     spacy is_valid  \n",
       "13       [ADV, PUNCT, ADJ, NOUN, NOUN, ADP, NOUN, NOUN,...   [True]  \n",
       "31       [PRON, VERB, ADJ, NOUN, SCONJ, DET, NOUN, VERB...   [True]  \n",
       "64       [ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...   [True]  \n",
       "67       [ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...   [True]  \n",
       "78       [PUNCT, NUM, PUNCT, NOUN, ADP, NOUN, VERB, ADP...   [True]  \n",
       "...                                                    ...      ...  \n",
       "2028828  [VERB, NOUN, AUX, DET, ADJ, NOUN, ADP, PROPN, ...   [True]  \n",
       "2028833  [SCONJ, NOUN, AUX, ADJ, PUNCT, PRON, AUX, PART...   [True]  \n",
       "2028847  [ADV, PUNCT, DET, ADJ, NOUN, NOUN, AUX, VERB, ...   [True]  \n",
       "2028864  [VERB, PUNCT, NUM, PUNCT, CCONJ, VERB, ADJ, NO...   [True]  \n",
       "2029254  [ADV, PUNCT, PRON, AUX, VERB, DET, VERB, NUM, ...   [True]  \n",
       "\n",
       "[76975 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:30.982454Z",
     "start_time": "2024-05-23T20:11:30.432627Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aedd9557f994d63806f6dd41d393a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/5629rv4577g4gcq9dn26mlbr0000gn/T/ipykernel_34988/1544203291.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matching['labels'] = df_matching.progress_apply(convert_labels_to_ids, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def convert_labels_to_ids(row):\n",
    "    labels  = [label2id[x] for x in row['spacy']]\n",
    "    return [-100] + labels + [-100] * (token_length - (len(labels) + 1))\n",
    "\n",
    "df_matching['labels'] = df_matching.progress_apply(convert_labels_to_ids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:30.997202Z",
     "start_time": "2024-05-23T20:11:30.985644Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>math_index</th>\n",
       "      <th>nltk_annotate</th>\n",
       "      <th>spacy</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>[recently, ,, higher, auslander, algebras, of,...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[RB, ,, JJR, NN, NNS, IN, NN, NNS, VBP, VBN, V...</td>\n",
       "      <td>[ADV, PUNCT, ADJ, NOUN, NOUN, ADP, NOUN, NOUN,...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 2, 13, 0, 8, 8, 1, 8, 8, 3, 3, 16, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[we, call, [MATH], krull-schmidt, if, each, ob...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[PRP, VBP, JJ, JJ, IN, DT, NN, VBZ, IN, DT, JJ...</td>\n",
       "      <td>[PRON, VERB, ADJ, NOUN, SCONJ, DET, NOUN, VERB...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 11, 16, 0, 8, 14, 6, 8, 16, 1, 6, 0, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[moreover, ,, this, d-kernel, appears, as, a, ...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...</td>\n",
       "      <td>[ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 2, 13, 6, 12, 16, 1, 6, 0, 8, 13, 1, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[moreover, ,, this, d-cokernel, appears, as, a...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...</td>\n",
       "      <td>[ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 2, 13, 6, 12, 16, 1, 6, 0, 8, 13, 1, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1375.html</td>\n",
       "      <td>Preliminaries</td>\n",
       "      <td>[(, 3, ), existence, of, [MATH], follows, in, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[(, CD, ), NN, IN, NN, VBZ, IN, DT, JJ, NN, IN...</td>\n",
       "      <td>[PUNCT, NUM, PUNCT, NOUN, ADP, NOUN, VERB, ADP...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 13, 9, 13, 8, 1, 8, 16, 1, 6, 0, 8, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028828</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[let, d, be, a, primitive, centralizer, of, u,...</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[VB, NN, VB, DT, JJ, NN, IN, JJ, CC, JJ, VB, D...</td>\n",
       "      <td>[VERB, NOUN, AUX, DET, ADJ, NOUN, ADP, PROPN, ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 16, 8, 3, 6, 0, 8, 1, 12, 5, 3, 3, 6, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028833</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[as, [ITALIC], is, invertible, ,, this, can, n...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[IN, NN, VBZ, JJ, ,, DT, MD, RB, VB, DT, NN, .]</td>\n",
       "      <td>[SCONJ, NOUN, AUX, ADJ, PUNCT, PRON, AUX, PART...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 14, 8, 3, 0, 13, 11, 3, 10, 3, 6, 8, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028847</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[finally, ,, a, square, matrix, [ITALIC], is, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[RB, ,, DT, JJ, NN, NN, VBZ, VBN, DT, NN, IN, ...</td>\n",
       "      <td>[ADV, PUNCT, DET, ADJ, NOUN, NOUN, AUX, VERB, ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 2, 13, 6, 0, 8, 8, 3, 16, 6, 8, 14, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028864</th>\n",
       "      <td>1024.html</td>\n",
       "      <td>Proof of Theorem 4.4\\n</td>\n",
       "      <td>[assuming, (, 2, ), and, taking, [MATH], yield...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[VBG, (, CD, ), CC, VBG, JJ, NNS, (, CD, ), .]</td>\n",
       "      <td>[VERB, PUNCT, NUM, PUNCT, CCONJ, VERB, ADJ, NO...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 16, 13, 9, 13, 5, 16, 0, 8, 13, 9, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029254</th>\n",
       "      <td>4226.html</td>\n",
       "      <td>Stability of steady-state</td>\n",
       "      <td>[next, ,, we, will, use, the, following, eight...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[JJ, ,, PRP, MD, VB, DT, JJ, CD, NNS, TO, VB, ...</td>\n",
       "      <td>[ADV, PUNCT, PRON, AUX, VERB, DET, VERB, NUM, ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-100, 2, 13, 11, 3, 16, 6, 16, 9, 8, 10, 16, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76975 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name                      title  \\\n",
       "13       1375.html               Introduction   \n",
       "31       1375.html              Preliminaries   \n",
       "64       1375.html              Preliminaries   \n",
       "67       1375.html              Preliminaries   \n",
       "78       1375.html              Preliminaries   \n",
       "...            ...                        ...   \n",
       "2028828  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028833  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028847  1024.html     Proof of Theorem 4.4\\n   \n",
       "2028864  1024.html     Proof of Theorem 4.4\\n   \n",
       "2029254  4226.html  Stability of steady-state   \n",
       "\n",
       "                                                    tokens math_index  \\\n",
       "13       [recently, ,, higher, auslander, algebras, of,...        [7]   \n",
       "31       [we, call, [MATH], krull-schmidt, if, each, ob...        [2]   \n",
       "64       [moreover, ,, this, d-kernel, appears, as, a, ...       [14]   \n",
       "67       [moreover, ,, this, d-cokernel, appears, as, a...       [14]   \n",
       "78       [(, 3, ), existence, of, [MATH], follows, in, ...        [5]   \n",
       "...                                                    ...        ...   \n",
       "2028828  [let, d, be, a, primitive, centralizer, of, u,...       [16]   \n",
       "2028833  [as, [ITALIC], is, invertible, ,, this, can, n...        [1]   \n",
       "2028847  [finally, ,, a, square, matrix, [ITALIC], is, ...        [5]   \n",
       "2028864  [assuming, (, 2, ), and, taking, [MATH], yield...        [6]   \n",
       "2029254  [next, ,, we, will, use, the, following, eight...       [15]   \n",
       "\n",
       "                                             nltk_annotate  \\\n",
       "13       [RB, ,, JJR, NN, NNS, IN, NN, NNS, VBP, VBN, V...   \n",
       "31       [PRP, VBP, JJ, JJ, IN, DT, NN, VBZ, IN, DT, JJ...   \n",
       "64       [RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...   \n",
       "67       [RB, ,, DT, JJ, VBZ, IN, DT, JJ, NN, (, IN, DT...   \n",
       "78       [(, CD, ), NN, IN, NN, VBZ, IN, DT, JJ, NN, IN...   \n",
       "...                                                    ...   \n",
       "2028828  [VB, NN, VB, DT, JJ, NN, IN, JJ, CC, JJ, VB, D...   \n",
       "2028833    [IN, NN, VBZ, JJ, ,, DT, MD, RB, VB, DT, NN, .]   \n",
       "2028847  [RB, ,, DT, JJ, NN, NN, VBZ, VBN, DT, NN, IN, ...   \n",
       "2028864     [VBG, (, CD, ), CC, VBG, JJ, NNS, (, CD, ), .]   \n",
       "2029254  [JJ, ,, PRP, MD, VB, DT, JJ, CD, NNS, TO, VB, ...   \n",
       "\n",
       "                                                     spacy is_valid  \\\n",
       "13       [ADV, PUNCT, ADJ, NOUN, NOUN, ADP, NOUN, NOUN,...   [True]   \n",
       "31       [PRON, VERB, ADJ, NOUN, SCONJ, DET, NOUN, VERB...   [True]   \n",
       "64       [ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...   [True]   \n",
       "67       [ADV, PUNCT, DET, PROPN, VERB, ADP, DET, ADJ, ...   [True]   \n",
       "78       [PUNCT, NUM, PUNCT, NOUN, ADP, NOUN, VERB, ADP...   [True]   \n",
       "...                                                    ...      ...   \n",
       "2028828  [VERB, NOUN, AUX, DET, ADJ, NOUN, ADP, PROPN, ...   [True]   \n",
       "2028833  [SCONJ, NOUN, AUX, ADJ, PUNCT, PRON, AUX, PART...   [True]   \n",
       "2028847  [ADV, PUNCT, DET, ADJ, NOUN, NOUN, AUX, VERB, ...   [True]   \n",
       "2028864  [VERB, PUNCT, NUM, PUNCT, CCONJ, VERB, ADJ, NO...   [True]   \n",
       "2029254  [ADV, PUNCT, PRON, AUX, VERB, DET, VERB, NUM, ...   [True]   \n",
       "\n",
       "                                                    labels  \n",
       "13       [-100, 2, 13, 0, 8, 8, 1, 8, 8, 3, 3, 16, 1, 1...  \n",
       "31       [-100, 11, 16, 0, 8, 14, 6, 8, 16, 1, 6, 0, 8,...  \n",
       "64       [-100, 2, 13, 6, 12, 16, 1, 6, 0, 8, 13, 1, 6,...  \n",
       "67       [-100, 2, 13, 6, 12, 16, 1, 6, 0, 8, 13, 1, 6,...  \n",
       "78       [-100, 13, 9, 13, 8, 1, 8, 16, 1, 6, 0, 8, 1, ...  \n",
       "...                                                    ...  \n",
       "2028828  [-100, 16, 8, 3, 6, 0, 8, 1, 12, 5, 3, 3, 6, 8...  \n",
       "2028833  [-100, 14, 8, 3, 0, 13, 11, 3, 10, 3, 6, 8, 13...  \n",
       "2028847  [-100, 2, 13, 6, 0, 8, 8, 3, 16, 6, 8, 14, 6, ...  \n",
       "2028864  [-100, 16, 13, 9, 13, 5, 16, 0, 8, 13, 9, 13, ...  \n",
       "2029254  [-100, 2, 13, 11, 3, 16, 6, 16, 9, 8, 10, 16, ...  \n",
       "\n",
       "[76975 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:32.750732Z",
     "start_time": "2024-05-23T20:11:30.999847Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381cd07469344d7a8a93a863b997b5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/61580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ef7107a9cf4ce2b1e0fe99f008d678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bd47c7345344fc952c4dd6442f608c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(df_matching))\n",
    "group_size = len(df_matching)\n",
    "dataset = ds.Dataset.from_pandas(df_matching)\n",
    "\n",
    "train_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = train_dataset['test'].train_test_split(test_size=0.3, seed=42)\n",
    "d = {'train': train_dataset['train'], 'test': test_dataset['train'], 'eval': test_dataset['test']}\n",
    "for key in d:\n",
    "    d[key].save_to_disk(f'full_valid_dataset_sentence-{group_size}/{key}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:11:41.102739Z",
     "start_time": "2024-05-23T20:11:32.751530Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a761d45c7040f081faa17c8a1f233d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/1952522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(df_not_matching))\n",
    "group_size = len(df_not_matching)\n",
    "dataset = ds.Dataset.from_pandas(df_not_matching)\n",
    "dataset.save_to_disk(f'full_invalid_dataset_sentence-{group_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senetence_with_label(d, label):\n",
    "    for i, row in d.iterrows():\n",
    "        for l, t in zip(row['spacy'], row['tokens']):\n",
    "            if l == label:\n",
    "                print(row['tokens'])\n",
    "                print(row['nltk_annotate'])\n",
    "                print(row['spacy'])\n",
    "                return row\n",
    "    print(\"None found\")\n",
    "get_senetence_with_label(df_matching, 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spacy_to_nltk(row):\n",
    "    tags = row['spacy']\n",
    "    nltk_tags = row['nltk_annotate']\n",
    "    math_ids = row['math_index']\n",
    "    return [nltk_tags[i] in spacy_to_nltk[tags[i]] for i in math_ids]\n",
    "\n",
    "row = {\n",
    "    'spacy': ['ADV', 'ADV', 'PUNCT', 'X', 'PUNCT'],\n",
    "    'nltk_annotate': ['RB', 'IN', ',', 'FW', 'NN'],\n",
    "    'math_index': [3]\n",
    "}\n",
    "\n",
    "check_spacy_to_nltk(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
